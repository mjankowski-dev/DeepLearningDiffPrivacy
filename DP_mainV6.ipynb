{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNFVMtUhMt7l"
   },
   "source": [
    "# Deep learning with Differential Privacy - Main script. Author: Reinier Vos (4663160 TUD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NenrAcsiM7Zl"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkMXve8XuN5X"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "  \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Normalization\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tqdm import tqdm # gives progress bar when loading\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.ticker as mticker\n",
    "import scipy.stats as sc\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "# verbosity \n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS/TO-DO\n",
    "- minibatches for sgd, to speed up optimization? - https://github.com/tensorflow/privacy/blob/master/tutorials/mnist_dpsgd_tutorial.py \n",
    "-\n",
    "-\n",
    "-\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Main Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "seed = 2\n",
    "std_pca = 7 #16 #4 # std for pca\n",
    "std_sgd = 4 # std for dp_sgd\n",
    "batch_size = 600 \n",
    "lr_sgd = 0.05 # [0.01,0.07] stable, best at 0.05\n",
    "C = 4 # gradient clipping bound\n",
    "gs = batch_size\n",
    "\n",
    "# moment accountant specific\n",
    "parameters_ma = {\"maxOrder\":32,\n",
    "                 \"sigma\": std_sgd,\n",
    "                 \"q\": batch_size/60000,\n",
    "                 \"T\":400}\n",
    "debug = True\n",
    "#'''\n",
    "deltaFixed = False\n",
    "epsFixed= True\n",
    "epsilon = 2\n",
    "th_delta = 100#10**-5 # epsilon fixed\n",
    "'''\n",
    "deltaFixed = True \n",
    "epsFixed= False\n",
    "delta = 10e-5\n",
    "th_epsilon = 2 # delta fixed\n",
    "'''\n",
    "allParameters = {**parameters_ma,\n",
    "                'seed' : seed,\n",
    "                'std_pca' :std_pca, \n",
    "                'std_sgd' : std_sgd,\n",
    "                'batch_size' : batch_size, \n",
    "                'lr_sgd' : lr_sgd, \n",
    "                'C' : C, \n",
    "                'deltaFixed' : deltaFixed, \n",
    "                'epsFixed': epsFixed, \n",
    "                'epsilon' : epsilon, \n",
    "                'th_delta' : th_delta, \n",
    "}\n",
    "'''\n",
    "allParameters = {**parameters_ma,\n",
    "                'seed' = seed,\n",
    "                'std_pca' =std_pca, \n",
    "                'std_sgd' = std_sgd,\n",
    "                'batch_size' = batch_size, \n",
    "                'lr_sgd' = lr_sgd, \n",
    "                'C' = C, \n",
    "                'deltaFixed' = deltaFixed, \n",
    "                'epsFixed'= epsFixed, \n",
    "                'delta' = delta, 'th_epsilon' = th_epsilon, \n",
    "}\n",
    "'''\n",
    "batches = 100\n",
    "np.random.seed(seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxorder = 32, with order array:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "keeping epsilon fixed\n",
      "moment accountant setup complete\n",
      "Delta fixed = False| Last delta = 7.3130754258017764e-06\n",
      "Epsilon fixed = True| Last epsilon = 2\n",
      "Fixed parameter will not be plotted \n",
      " NOTE: Iteration arrays are returned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.61157896e-28, 1.61938465e-28, 1.62722815e-28, ...,\n",
       "        7.28717560e-06, 7.30011403e-06, 7.31307543e-06]),\n",
       " array([2, 2, 2, ..., 2, 2, 2]),\n",
       " array([32, 32, 32, ..., 17, 17, 17]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf5UlEQVR4nO3deXhdV3nv8e/PkjzKsTwojoc4zmhIKImNmxDSQggEQsiFltLbpC0lkDaltJTxtlB6W9pbShnuLbS0gJuGMAYIBAIpEAiQMmXADg7YSZzYjuPZli3JkiXLkuz3/rGXnGNFw7F0hn3k3+d5zqN99viuvc95tc7aa++tiMDMzPJrUrUDMDOzkTlRm5nlnBO1mVnOOVGbmeWcE7WZWc45UZuZ5ZwT9QQk6a8k3ZSGl0oKSfXVjms0km6R9A9FzrtF0ovLHVO5SfqWpNdWOYaDks6qZgw2stx/ee3ERcQ/VjuGSpL0HuCciPj9asdyoiLiZQPDkq4H/jAifq1c25N0D/DZiLipIIbGcm3PSsM1ais7ZU76z5qkujKv3xWvCeqk//JUm6SFkr4iqUXSE5L+vGDaeyR9WdIXJXVKelDShQXT/1LSjjRtg6QXFSz32RG293VJrZI2SvqjQdv7kqRPp3Wul7RyhNifJ+lnkg6kv88rmHaPpPdK+gnQDTztp7Wk5alMnZK+CEwdNP0aSWsltUv6qaRnD7GOq4C/An4n/YR/KI1/naRH0ro3S/rjEcoxSdJfS3pS0t5U/llp2rck/dmg+R+S9Ko0/AxJ3037c4Ok/1kw3y2SPibpm5K6gBcOse17JP2hpGcCHwcuTeVoT9OnSPqQpK2S9kj6uKRpadrlkranz8Fu4JOSZku6M32e2tLw4jT/e4FfBz6atvHRND4knZOGZ6Xyt6T98dcD/2QlXS/pxymetvR5Pe4XQdrXnWna7w23z+0ERYRfVXqR/aNcA/wNMJksmW0GXpqmvwfoA14NNADvAJ5Iw8uAbcDCNO9S4OyC5T5bMD6A+vT+h8C/kyXFi4AW4IqC5XqAq4E64H3AfcPEPgdoA15D1oR2XXo/N02/B9gKXJCmNwxafjLwJPDWVJ5Xp7L+Q5q+HNgLXJJieS2wBZiSpm8BXjy4vAXrfzlwNiDgBWT/LFYMU5bXAxvT/m8Ebgc+k6b9AfCTgnnPB9qBKcCMdAxel8q4HNgHnJ/mvQU4AFyWjvXUIbZ9D1lzB8D1wI8HTf9n4Otpf88EvgG8L027HOgH3p/imQbMBX4LmJ7mvw342lDbKxgXZE1HAJ8G7kjLLgUeA24oiK8P+KN0TP4E2Jn28QygA1iW5l0AXFDt79hEeZUzCd2cvmjrSrS+JcB3gEeAh4Gl1d55JSjTJcDWQePeBXwyDb+HgkSZvuy7yGpF56T9+2KengSPJS4KEjVwOnAEmFkw7/uAWwqWu7tg2vnAoWFifw3wwKBx9wLXp+F7gL8foezPH/iSF4z7KU8l6o8B/2fQMhuAF6ThLYyQqIfY3teANw8z7XvAGwveL0sJqT4lrC7gjDTtvcDNafh3gB8NWtcngL9Nw7cAnx4lrnsYJlGnBNhF+gecxl0KPJGGLwd6GeIfQMH8FwFtQ22vYFykz1NdWt/5BdP+GLinIL6NBdOmp2VPI0vU7WT/JKZV+7s10V7lbPq4BbiqhOv7NPDBiHgmcDFZkqp1ZwAL00/79vRz96+A+QXzbBsYiIijwHayWvRG4C1kSWqvpC9IWjjK9hYCrRHRWTDuSWBRwfvdBcPdwFQN3fa5MC1baPC6tjG8hcCOSN/4guUHnAG8fdC+OT0tNypJL5N0X2qSaCf7lTBvhFgKt/0kWZKen/bVfwHXpmnXAZ8riPGSQTH+HlniGjDSPhhNM1kyXFOw/m+n8QNaIqJn4I2k6ZI+kZotOsh+QTWpuPbxeWS/bgbviyE/HxHRnQYbI6KL7B/XG4Bdkv5L0jOKLaiNrGyJOiJ+CLQWjpN0tqRvS1oj6UfFHkhJ55P9dP9uWvfBgg9JLdtGVjtqKnjNjIirC+Y5fWAgtRUuJquJEhGfj6yHwBlkNZv3j7K9ncAcSTMLxi0Bdowh9p1pu4UGr2ukWzPuAhZJ0qDlB2wD3jto30yPiFuHWNdx25E0BfgK8CGyZNsEfJOshlpMWZaQNSnsSe9vBa6TdClZk9EPCmL870ExNkbEnwwX2ygGz7sPOETWhDCw/llxfC+Nwcu8newXwSURcQrZLxd4quwjxbOP7JfE4H1R1OcjIu6KiCvJmj0eBf6jmOVsdJU+mbgKeFNEPIesvfXfi1zuPKBd0u2Sfi7pg0XWEPLuAaAznQyaJqlO0rMk/WrBPM+R9KpUq30LcBi4T9IySVekpNRD9oU+OtLGImIbWfPC+yRNVXZy7gZgyBOPo/gmcJ6k35VUL+l3yJpK7ixy+XvJkuGfS2pIJ+cuLpj+H8AbJF2izAxJLx/0T2bAHmCpnupZMpmszbYF6E8nvF4yQiy3Am+VdKakRuAfgS9GRH9BWc8A/j6NH9jPd6Z98JpUhgZJv5pODI7FHmCxpMlw7BfUfwD/LOlUAEmLJL10hHXMJPsstEuaA/ztENsYss90RBwBvgS8V9JMSWcAb6OIz4ek+ZJeKWkG2Wf0IKN8Hq14FUvU6QvwPOA2SWvJ2vIWpGmvkrRuiNddafF6snbZdwC/SvZBu75SsZdL+mJcQ9aO+ARZjeYmYFbBbHeQ/aQcOHH3qojoI0tE/5SW2Q2cSta+PZrryNqtdwJfJWtPvXsMse9Psb8d2A/8BXBNROwrcvle4FVkx7GVrIy3F0xfTXbS6qNkZd/I8Mf8tvR3v6QHU3PFn5MlnTbgd8lOyA3nZuAzZM0ET5D943tTQSyHU2wvBj5fML6T7B/AtWT7czdPndgbi+8D64Hdkgb241+Slf2+1JRxN1mNeTgfJjupuA+4j6yppNBHgFenXhv/MsTybyJrF98M/JisvDcXEfsksqS+k+x4voDsZKOVgI5vIizxyqWlwJ0R8SxJpwAbImLBGNbzXOD9EfGC9P41wHMj4k9LGnDOqIYv5DCz0qlYjToiOoAnJP02HLsI4sJRFhvwM7ITIgMnUa4g6/lhZjbhlS1RS7qVrB1ymbJO+TeQnRG/QdlFCeuBVxazrtRE8A7ge5J+SXZixCcqzOykUNamDzMzGz9fQm5mlnNluYnLvHnzYunSpeVYtZnZhLRmzZp9EdE81LSyJOqlS5eyevXqcqzazGxCkjT4St9j3PRhZpZzTtRmZjnnRG1mlnNO1GZmOedEbWaWc07UZmY550RtZpZzTtRmZiVw98N7+Ph/byrLup2ozcxK4K71u7nlJ1vKsm4najOzEmjr7qNpekNZ1u1EbWZWAu3dvcyePrks63aiNjMrgbbuXmbPcI3azCy32rv7aHKN2swsnyKC9kN9NE2rUo1a0jJJawteHZLeUpZozMxqUOfhfo4cjbK1UY96P+qI2ABcBCCpDtgBfLUs0ZiZ1aD2rj6A3PT6eBGwKSKGvcG1mdnJpq27FyA3vT6uBW4daoKkGyWtlrS6paVl/JGZmdWIY4m62r0+JE0GXgHcNtT0iFgVESsjYmVz85CP/TIzm5DauweaPqpfo34Z8GBE7ClLJGZmNSpPTR/XMUyzh5nZyaytuw8JZlWrex6ApBnAlcDtZYnCzKyGtXf3csrUBuomqSzrH7V7HkBEdAFzyxKBmVmNa+vuY3aZuuaBr0w0Mxu39u5eZpWpfRqcqM3Mxq3dNWozs3xrK+MtTsGJ2sxs3NrL+NAAcKI2MxuX3v6jHDzc7xq1mVletR8auNjFNWozs1wq9+Xj4ERtZjYubV3lvXwcnKjNzMalrbu896IGJ2ozs3FpTzdkcqI2M8up9kNZjdpNH2ZmOdXW3cvkuklMn1xXtm04UZuZjUN7V3axi1SeO+eBE7WZ2biU+/JxcKI2MxuXcl8+Dk7UZmbj4hq1mVnOtXX3le3p4wOcqM3MxigiaO/uLevl41D8MxObJH1Z0qOSHpF0aVmjMjOrAQcP99N/NGgq00NtBxT1zETgI8C3I+LVkiYD08sYk5lZTWjrShe7zChvjXrURC1pFvB84HqAiOgFessalZlZDdjfdRiAuWVO1MU0fZwJtACflPRzSTdJmjF4Jkk3SlotaXVLS0vJAzUzy5vWdOe8OTlI1PXACuBjEbEc6ALeOXimiFgVESsjYmVzc3OJwzQzy5/9KVHPnTGlrNspJlFvB7ZHxP3p/ZfJEreZ2UntWI26sco16ojYDWyTtCyNehHwcFmjMjOrAa1dvUyun8SMMt6QCYrv9fEm4HOpx8dm4HXlC8nMrDbsP9jL3BmTy3pDJigyUUfEWmBlWSMxM6sxrV2Hy34iEXxlopnZmLV29TpRm5nl2f6u3rL3oQYnajOzMctq1OXtmgdO1GZmY9LTd4Tu3iPMLXPXPHCiNjMbk0pdlQhO1GZmY+JEbWaWc09dPu5EbWaWS63pznmuUZuZ5dT+g5W5IRM4UZuZjUlrVy/1k8Qp04q9E8fYOVGbmY1Ba1cvsytwnw9wojYzG5NKXZUITtRmZmOy7+Bh5jWWv30anKjNzMakpfMwzTOdqM3McikiaOk8zLwKXD4OTtRmZifs4OF+DvcfdY3azCyvWjqzi12cqM3McupYom6cWpHtFdVTW9IWoBM4AvRHhB/LZWYnrZaDla1Rn8glNS+MiH1li8TMrEa46cPMLOf2HTxM3STRNK2hItsrNlEH8B1JayTdONQMkm6UtFrS6paWltJFaGaWMwNd8yZNKv/l41B8ov61iFgBvAz4U0nPHzxDRKyKiJURsbK5ubmkQZqZ5UklL3aBIhN1ROxIf/cCXwUuLmdQZmZ51nLwMM0VunwcikjUkmZImjkwDLwEWFfuwMzM8qrSNepien3MB76abuVXD3w+Ir5d1qjMzHLq6NFg38HefCXqiNgMXFiBWMzMcq/9UB9Hjka+mj7MzOwpA32o5+XtZKKZmWWeunzcidrMLJf2dvYAlbsqEZyozcxOyO6OLFGfNqsyN2QCJ2ozsxOy50APM6fWM31y+Z8+PsCJ2szsBOzu6OG0UypXmwYnajOzE7K743BFmz3AidrM7ITsOeAatZlZbvUfOcrezh7XqM3M8mrfwV6OBsx3jdrMLJ+Odc1zojYzy6fdByrfhxqcqM3MirYn1ajd9GFmllO7O3poqBNzZ0yu6HadqM3MirTnQA+nzpxasWclDnCiNjMr0u6OynfNAydqM7Oi7a7CxS7gRG1mVpSIYHdHT8VPJMIJJGpJdZJ+LunOcgZkZpZHBw710d17hIVNOU7UwJuBR8oViJlZnm1vOwTA4tnTKr7tohK1pMXAy4GbyhuOmVk+7WjPEvWipukV33axNeoPA38BHB1uBkk3SlotaXVLS0spYjMzy40dqUa9KI81aknXAHsjYs1I80XEqohYGRErm5ubSxagmVke7Gg/xNSGScye3lDxbRdTo74MeIWkLcAXgCskfbasUZmZ5cyOtkMsapqGVNmLXaCIRB0R74qIxRGxFLgW+H5E/H7ZIzMzy5Ed7YdYNLvy7dPgftRmZkXZ0Z7VqKvhhB6jGxH3APeUJRIzs5zq7u2ntau3Kl3zwDVqM7NR7TzWNc+J2swsl7ZXsWseOFGbmY1qZ3v2wADXqM3McmpHezf1k1SVGzKBE7WZ2ai2tR7itFlTqavwAwMGOFGbmY3iydZuzphbnT7U4ERtZjaqrfu7OGPujKpt34nazGwEHT19tHX3ccYc16jNzHJp6/5uADd9mJnl1Zb9XQAsmeOmDzOzXHoy1aiXuEZtZpZPW/d3M69xMo1TTujWSCXlRG1mNoInW6vb4wOcqM3MRrR1f3dVe3yAE7WZ2bB6+o6wq6Onqu3T4ERtZjas7W3dRFS3ax44UZuZDWvLvoE+1G6jNjPLpU0tBwE4u7mxqnGMmqglTZX0gKSHJK2X9HeVCMzMrNo27j1I88wpzJrWUNU4iukYeBi4IiIOSmoAfizpWxFxX5ljMzOrqk0tBzm7ubrNHlBEjToyB9PbhvSKskZlZlZlEcGmlq6qN3tAkW3UkuokrQX2At+NiPuHmOdGSaslrW5paSlxmGZmlbW/q5cDh/pqJ1FHxJGIuAhYDFws6VlDzLMqIlZGxMrm5uYSh2lmVlmb9qYTiafWSKIeEBHtwA+Aq8oSjZlZTmxMPT7OqYVELalZUlMangZcCTxa5rjMzKpq094upjXUsaBKD7QtVEyvjwXApyTVkSX2L0XEneUNy8ysuja1HOSs5hlMqtIDbQuNmqgj4hfA8grEYmaWGxv3HuQ5Z8yudhiAr0w0M3uarsP97Gg/xLk5aJ8GJ2ozs6d5PPX4OO+0mVWOJONEbWY2yGO7OwFYNt+J2swslx7b08nUhkmcXuUHBgxwojYzG2TDnk7OObWRuhz0+AAnajOzp3lsTyfn5aTZA5yozcyOc6C7jz0dh3PTPg1O1GZmx3lsb3YiMS89PsCJ2szsOBtSjw83fZiZ5dTjezppnFLPwlnVv8fHACdqM7MCG/Z0ct78RqR89PgAJ2ozs2Migod3drDstFOqHcpxnKjNzJLtbYfo6OnnWYucqM3Mcmn9zgMAPGvhrCpHcjwnajOzZN2ODuomiWU56poHTtRmZses23mAc09tZGpDXbVDOY4TtZlZsn5nBxfkrNkDnKjNzADY29FDS+fh3J1IhOIebnu6pB9IeljSeklvrkRgZmaVtC6dSMxjjbqYh9v2A2+PiAclzQTWSPpuRDxc5tjMzCrmoW0HmCQ4f2EN1qgjYldEPJiGO4FHgEXlDszMrJIe3NrGefNn0jilmPprZZ1QG7WkpWRPJL9/iGk3SlotaXVLS0uJwjMzK7+jR4O129pZkZOnjg9WdKKW1Ah8BXhLRHQMnh4RqyJiZUSsbG5uLmWMZmZltbHlIJ09/axYUsOJWlIDWZL+XETcXt6QzMwq68En2wBYvqSpuoEMo5heHwL+E3gkIv5f+UMyM6usB7e20TS9gbPmzah2KEMqpkZ9GfAa4ApJa9Pr6jLHZWZWMQ9ubWf56U25urVpoVFPb0bEj4F8Rm9mNk6tXb1s3HuQ37hoYbVDGZavTDSzk9r9m/cDcOnZc6scyfCcqM3spHbv5v1Mn1zHsxc3VTuUYTlRm9lJ7d5N+1m5dA4NdflNh/mNzMyszPZ29vD43oM8L8fNHuBEbWYnsfs2twJw6VlO1GZmufTTjfuYOaWeC3J4I6ZCTtRmdlKKCH6wYS+/ft486nPcPg1O1GZ2klq/s4M9HYd54bJTqx3KqJyozeyk9INH9wJwuRO1mVk+fX/DXi5cPIvmmVOqHcqonKjN7KSz/+Bh1m5r54XPyH9tGpyozewk9O31u4mAK8+fX+1QiuJEbWYnnTvW7uScUxs5f0G+u+UNcKI2s5PKzvZDPPBEK6+8cGFub2s6mBO1mZ1UvvHQTgBekePbmg7mRG1mJ5U71u7kotObOGNuPp/mMhQnajM7aTy+p5OHd3XwyhqqTYMTtZmdRO5Yu5NJgpc/e0G1QzkhxTzc9mZJeyWtq0RAZmblcPRocMdDO7jsnHmcOnNqtcM5IcXUqG8BripzHGZmZXXv5v1saz3Eb61YXO1QTtioiToifgi0ViAWM7OyufWBrcya1sBVzzqt2qGcsJK1UUu6UdJqSatbWlpKtVozs3Fr7erlO+v38JvLFzG1oa7a4ZywkiXqiFgVESsjYmVzc3OpVmtmNm63rd5G75GjXHfxkmqHMibu9WFmE1rfkaPc8tMtXHLmHJadNrPa4YyJE7WZTWjfeGgnuw708IYXnF3tUMasmO55twL3AsskbZd0Q/nDMjMbv4hg1Q83c978Ri5fVrtNsvWjzRAR11UiEDOzUvv2ut08uruT//vbF9bMDZiG4qYPM5uQ+o8c5UPf2cC5pzbyG8sXVTuccXGiNrMJ6SsPbmdTSxfveOky6ibVbm0anKjNbAI60N3HB+/awIolTbykRp7iMpJR26jNzGrNB+56lNauXj71+otrum16gGvUZjahrN7Syucf2MrrLjuTCxbOqnY4JeFEbWYTxoFDfbz5C2tZPHsab73yvGqHUzJu+jCzCSEiePdXf8nujh5ue8OlNE6ZOOnNNWozmxD+/Z5N3PmLXbztyvNYsWR2tcMpKSdqM6t53/zlLj541wZeceFC3nh57V4qPhwnajOraWuebOVtX1rLiiVNfODVz54QvTwGc6I2s5r14NY2Xnvzz1gwaxqr/mBlTd5ruhhO1GZWk/77sRb+4D8fYF7jZG79o+cyr3FKtUMqGydqM6spEcEtP3mC19/yMxbPnsatNz6X02bV1sNqT9TE6b9iZhNeS+dh3vmVX/C9R/fy4meeyoevXT6huuENZ+KX0Mxq3uH+I3zm3if51+9v5FDfEf7mmvO5/nlLmVTjN1sqlhO1meVWb/9RvvHQTv757sfY3naI55/XzP9++TM5d35tPlJrrJyozSx3drQf4ms/38Fn7n2S3R09PHPBKXzmhl/h18+t3ae0jIcTtZlVXf+Ro6zb2cF9m/dz98N7WP1kGwCXnTOX9/3Wr/CCc5tPmmaOoRSVqCVdBXwEqANuioh/KmtUZjZh9fQdYWtrN4/s6uDR3Z2s39nBmi2tdPUeAeAZp83kf710Gf/j2QtZMnd6laPNh1ETtaQ64N+AK4HtwM8kfT0iHi53cGaWLxFB35Gg98hRevsLXkeO0NN3lK7D/XT09HPgUB8HDvXRcaiP9u5edh7oYdeBQ+xq72F/V++x9TXUibObG/nNFYt47llzueTMuTTPnLj9oceqmBr1xcDGiNgMIOkLwCuBkifqa/71R/T0HR12ekSMuPzIU0efYbTlx7v9URYnRljDqMuOWvjRlq9e2YpbfnzbH20N499+mfdfDj77/UezBH2in7VTptazYNY0FjRN5VcWNbFw1lROnzOdZyyYyVnzGplc78s5RlNMol4EbCt4vx24ZPBMkm4EbgRYsmTJmII5p7mRviOjfApGaaYarRVrtPsAjL58dbc/0gwaZenxxz7a8uPc/ngKX8z6R1t7ucs36vbH1wZb7vjrJ4nJ9ZOYXDeJKQ3Z38n1ddm4NL5xSj2zpjUwa1oDp0yrZ+bUhpp/XmEelOxkYkSsAlYBrFy5ckz1uw9fu7xU4ZiZTRjF/ObYAZxe8H5xGmdmZhVQTKL+GXCupDMlTQauBb5e3rDMzGzAqE0fEdEv6c+Au8i6590cEevLHpmZmQFFtlFHxDeBb5Y5FjMzG4L7xZiZ5ZwTtZlZzjlRm5nlnBO1mVnOabRLU8e0UqkFeHKMi88D9pUwnEqr9fjBZciLWi9DrccPlS3DGREx5H1cy5Kox0PS6ohYWe04xqrW4weXIS9qvQy1Hj/kpwxu+jAzyzknajOznMtjol5V7QDGqdbjB5chL2q9DLUeP+SkDLlrozYzs+PlsUZtZmYFnKjNzHIuN4la0lWSNkjaKOmd1Y6nkKTTJf1A0sOS1kt6cxo/R9J3JT2e/s5O4yXpX1JZfiFpRcG6Xpvmf1zSaytcjjpJP5d0Z3p/pqT7U5xfTLexRdKU9H5jmr60YB3vSuM3SHppheNvkvRlSY9KekTSpTV4DN6aPkPrJN0qaWrej4OkmyXtlbSuYFzJ9ruk50j6ZVrmXzTeR90UF/8H0+foF5K+KqmpYNqQ+3a4HDXc8SupiKj6i+z2qZuAs4DJwEPA+dWOqyC+BcCKNDwTeAw4H/gA8M40/p3A+9Pw1cC3yJ6+9Fzg/jR+DrA5/Z2dhmdXsBxvAz4P3Jnefwm4Ng1/HPiTNPxG4ONp+Frgi2n4/HRspgBnpmNWV8H4PwX8YRqeDDTV0jEge6zdE8C0gv1/fd6PA/B8YAWwrmBcyfY78ECaV2nZl1Ug/pcA9Wn4/QXxD7lvGSFHDXf8SlqGSnxAi9iRlwJ3Fbx/F/Cuasc1Qrx3kD2VfQOwII1bAGxIw58AriuYf0Oafh3wiYLxx81X5pgXA98DrgDuTF+KfQUf1mPHgOze45em4fo0nwYfl8L5KhD/LLIkp0Hja+kYDDx/dE7ar3cCL62F4wAsHZToSrLf07RHC8YfN1+54h807TeBz6XhIfctw+Sokb5HpXzlpeljqAfoLqpSLCNKPz+XA/cD8yNiV5q0G5ifhocrTzXL+WHgL4CBx7zPBdojon+IWI7FmaYfSPNXM/4zgRbgk6n55iZJM6ihYxARO4APAVuBXWT7dQ21dRwGlGq/L0rDg8dX0uvJavJw4vGP9D0qmbwk6pogqRH4CvCWiOgonBbZv9Nc9nWUdA2wNyLWVDuWcagn+/n6sYhYDnSR/eQ+Js/HACC1476S7J/OQmAGcFVVgyqBvO/3kUh6N9APfK7asYwkL4k69w/QldRAlqQ/FxG3p9F7JC1I0xcAe9P44cpTrXJeBrxC0hbgC2TNHx8BmiQNPOWnMJZjcabps4D9VPc4bQe2R8T96f2XyRJ3rRwDgBcDT0RES0T0AbeTHZtaOg4DSrXfd6ThwePLTtL1wDXA76V/NnDi8e9n+ONXOuVs1zqB9qN6spMLZ/JUQ/0F1Y6rID4BnwY+PGj8Bzn+hMoH0vDLOf6EygNp/ByydtbZ6fUEMKfCZbmcp04m3sbxJ0HemIb/lONPYn0pDV/A8SdaNlPZk4k/Apal4fek/V8zxwC4BFgPTE9xfQp4Uy0cB57eRl2y/c7TTyZeXYH4rwIeBpoHzTfkvmWEHDXc8Stp/JX4gBa5I68m602xCXh3teMZFNuvkf20+wWwNr2uJmuf+h7wOHB3wQdPwL+lsvwSWFmwrtcDG9PrdVUoy+U8lajPSl+SjenDNiWNn5reb0zTzypY/t2pXBso8dn5ImK/CFidjsPX0he+po4B8HfAo8A64DMpIeT6OAC3krWp95H9srmhlPsdWJn2xybgoww6YVym+DeStTkPfJ8/Ptq+ZZgcNdzxK+XLl5CbmeVcXtqozcxsGE7UZmY550RtZpZzTtRmZjnnRG1mlnNO1GZmOedEbWaWc/8f1oLmdMhD1gwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accountant = moment_accountant(seed, parameters_ma, deltaFixed = deltaFixed, epsFixed= epsFixed, debug = debug, epsilon = epsilon, th_delta = th_delta)\n",
    "#for i in range(12500):\n",
    "for i in range(80000):\n",
    "    accountant.compute_deltaEps()\n",
    "accountant.plot_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtcG5Of7M-IV"
   },
   "source": [
    "## Load and Preprocess Data\n",
    "We frist load the MNIST dataset using Tensorflow Datasets. This dataset has 28 x 28 grayscale images of digits belonging to 10 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1qm4y2FmvWJ"
   },
   "source": [
    "train_data, info = tfds.load(\"mnist\", split = \"train\", with_info = True, data_dir='./data/', download=True)\n",
    "test_data = tfds.load(\"mnist\", split = \"test\", data_dir='./data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "x_train = x_train.reshape(x_train.shape[0],784)\n",
    "x_test = x_test.reshape(x_test.shape[0],784)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "covar = tf.cast(tf.einsum('ji,jk->ik', x_train, x_train), 'float32') # covariance matrix used for pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batches\n",
    "indices = np.arange(0,len(x_train))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_train_batches = np.array_split(x_train[indices,:], batches)\n",
    "y_train_batches = np.array_split(y_train[indices], batches)\n",
    "train = list(zip(x_train_batches, y_train_batches))\n",
    "x_test_batches = np.array_split(x_test, batches)\n",
    "y_test_batches = np.array_split(y_test, batches)\n",
    "test = list(zip(x_test_batches, y_test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbliOEMHNiug"
   },
   "outputs": [],
   "source": [
    "class_names = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sn718Y0LOIaY"
   },
   "source": [
    "Next, you normalize the images by dividing them by 255.0 so as to make the pixels fall in the range (0, 1). You also reshape the data so as to flatten the 28 x 28 pixel array into a flattened 784 pixel array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxwzgw3BmkoD"
   },
   "source": [
    "def format_image(data):        \n",
    "    image = data[\"image\"]\n",
    "    image = tf.reshape(image, [-1]) ## same as keras.layers.Flatten()\n",
    "    image = tf.cast(image, 'float32')\n",
    "    image = image / 255.0\n",
    "    image = tf.math.l2_normalize(image, axis=-1)\n",
    "    #image = image / 255.0\n",
    "    return image, data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c26dmIL5nmNU"
   },
   "source": [
    "train_data = train_data.map(format_image) # preprocesses\n",
    "test_data = test_data.map(format_image) # preprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ws3N-uOgOnMf"
   },
   "source": [
    "Now you shuffle and batch your training and test datasets before feeding them to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9qdsNPen5-F"
   },
   "source": [
    "#train_data = tf.data.Dataset(x_train)\n",
    "#test_data = tf.data.Dataset(x_test)\n",
    "\n",
    "train = train_data.shuffle(buffer_size=batch_size*4).batch(batch_size) # memory management - batches are drawn from 1024 selected - if selected samples are replaced by unseen samples\n",
    "\n",
    "test =  test_data.batch(batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuCf0s7eOxKQ"
   },
   "source": [
    "## Define the Model - DP for MNIST as in paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP PCA layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DP_PCA(tf.keras.layers.Layer):\n",
    "    def __init__(self, pca_components, seed, std, covar):\n",
    "        super(DP_PCA, self).__init__()\n",
    "        self.pca_components = pca_components\n",
    "        self.seed = seed\n",
    "        self.std = std\n",
    "        self.covar = covar\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        a = 1 # placeholder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #inputs = tf.linalg.normalize(inputs, ord=2, axis=-1)\n",
    "        #inputs = tf.math.l2_normalize(inputs, axis=-1)\n",
    "        #covar = tf.einsum('ji,jk->ik', inputs, inputs)\n",
    "        #print(tf.shape(covar))\n",
    "        # add noise\n",
    "        covar = self.covar # copy\n",
    "        shape = tf.shape(covar)\n",
    "        noise = tf.random.normal(shape, mean = 0, stddev = self.std, dtype=tf.dtypes.float32, seed=self.seed)\n",
    "        covar += noise\n",
    "        # add vectors\n",
    "        e_values, e_vectors = tf.linalg.eigh(covar)\n",
    "        return tf.einsum('ij,jk->ik', inputs, e_vectors[:,-self.pca_components:])\n",
    "        #return tf.einsum('ji,ik->jk', inputs, e_vectors[:,-self.pca_components:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HU3qcM9WBcMh"
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    inputs = tf.keras.Input(shape=(784,), name='digits')\n",
    "    #x = tf.keras.layers.Normalization(axis=-1)(inputs) # normalization\n",
    "    x = DP_PCA(60, seed, std_pca, covar)(inputs)\n",
    "    #x = DP_PCA(60, seed, std_pca)(x)\n",
    "    #x = tf.keras.layers.Dense(1000, activation='relu', name='dense_1')(inputs)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu', name='dense_1')(x)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = base_model()\n",
    "z = np.random.rand(28*28)\n",
    "z = tf.constant(z)\n",
    "zout = model(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxaHy1NYPGSb"
   },
   "source": [
    "## Define Optimizer and Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5B3vh6fs84i"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate = lr_sgd) # [0.01,0.07] stable, best at 0.05\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.compat.v1.losses.Reduction.NONE)\n",
    "#loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#loss_object = lambda t,p : tf.reduce_sum(tf.math.square(tf.squeeze(tf.cast(tf.one_hot(t, 10), tf.float32))- p), axis = -1)\n",
    "#loss_object = lambda t,p : tf.reduce_sum(tf.math.square(tf.squeeze(tf.cast(tf.one_hot(t, 10), tf.float32))- p), axis = -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y1 = tf.constant([[1],[3]])\n",
    "x1 = tf.constant([[0,0.1,0.2,0.1],[0,0.1,0.2,0.1]])\n",
    "print(tf.squeeze(tf.cast(tf.one_hot(y1, 4), tf.float32)))\n",
    "\n",
    "loss_object = lambda t,p : tf.reduce_sum(tf.math.square(tf.squeeze(tf.cast(tf.one_hot(t, 4), tf.float32))- p), axis = -1) # tf.reduce_sum(tf.math.square(tf.math.subtract(tf.cast(tf.one_hot(t, 4), tf.float32),p)), axis = -1) \n",
    "l = loss_object(y1, x1)\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1fJsdYIPTb8"
   },
   "source": [
    "## Define Metrics & Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Pa_x-5-CH_V"
   },
   "outputs": [],
   "source": [
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment accountant class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moment_accountant():\n",
    "    def __init__(self,seed, params: dict,deltaFixed = False, epsFixed= False, debug = False, **kwargs):\n",
    "        \n",
    "        # moment accountant hyperparameters\n",
    "        self.mixN = 10000 # samples for mixture of moment arrays\n",
    "        self.debug = debug\n",
    "        self.seed = seed\n",
    "        \n",
    "        # constants \n",
    "        self.maxOrder = params[\"maxOrder\"] # maximum moment order \n",
    "        self.lambd = np.arange(1,self.maxOrder+1)\n",
    "        #self.lambd = np.array([0])\n",
    "        self.lambdaN = len(self.lambd) # number of lambdas to check\n",
    "        print(f\"Maxorder = {self.maxOrder}, with order array:\")\n",
    "        print(self.lambd)\n",
    "        self.sigma = params[\"sigma\"]\n",
    "        self.q = params[\"q\"]\n",
    "        self.T = params[\"T\"]\n",
    "        \n",
    "        # booleans \n",
    "        self.deltaFixed = deltaFixed\n",
    "        self.epsFixed = epsFixed\n",
    "        \n",
    "        if self.deltaFixed:\n",
    "            if self.epsFixed:\n",
    "                raise Exception(\"Choose ONLY epsilon or delta as fixed\")\n",
    "            # in case delta is held fixed\n",
    "            print(\"keeping delta fixed\")\n",
    "            self.delta = kwargs[\"delta\"]\n",
    "            self.th_epsilon = kwargs[\"th_epsilon\"]\n",
    "        elif self.epsFixed:\n",
    "            # in case epsilon is held fixed\n",
    "            print(\"keeping epsilon fixed\")\n",
    "            self.epsilon = kwargs[\"epsilon\"]\n",
    "            self.th_delta = kwargs[\"th_delta\"]\n",
    "        else:\n",
    "            raise Exception(\"Choose EITHER epsilon or delta as fixed\")\n",
    "        \n",
    "        #self.e1_mu0, self.e1_mu, self.e2_mu0, self.e2_mu = self._setup_mixNormNP() # obtain random sample arrays NUMPY\n",
    "        self.e1_mu0, self.e1_mu, self.e2_mu0, self.e2_mu = self._setup_mixNormTF() # obtain random sample arrays TENSORFLOW\n",
    "        self.alpha = self._compute_moment(self.lambd)\n",
    "        \n",
    "        # initializations \n",
    "        self.alphaSum = 0 # moment\n",
    "        self.lambdArgmin = []\n",
    "        self.iterations = 0\n",
    "        self.deltaList = []\n",
    "        self.epsList = []\n",
    "        # =================================\n",
    "        print(\"moment accountant setup complete\")\n",
    "        \n",
    "    def _setup_mixNormTF(self):\n",
    "        '''\n",
    "        Mixture of gaussians by tensorflow, so no assumptions used\n",
    "        https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Mixture\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        CHECKED - WORKING CORRECTLY\n",
    "        '''\n",
    "        # setup normal dis & mixture of normals arrays\n",
    "        np.random.seed(self.seed) # set seed\n",
    "        mu_0 = np.random.normal(0, self.sigma, (self.mixN))\n",
    "        # analytical mean & var for mix\n",
    "        \n",
    "        # setup gaussian mixture\n",
    "        dismix_mu = tfp.distributions.Mixture(cat=tfp.distributions.Categorical(probs=[1.-self.q, self.q]),\n",
    "                                    components=[tfp.distributions.Normal(loc=0., scale=self.sigma),\n",
    "                                                tfp.distributions.Normal(loc=1., scale=self.sigma)])\n",
    "        mu = dismix_mu.sample(sample_shape=(self.mixN), seed=self.seed).numpy()\n",
    "\n",
    "        # find pdf values for z's \n",
    "        e1_mu0 = sc.norm.pdf(mu_0,loc = 0, scale = self.sigma)\n",
    "        e1_mu = dismix_mu.prob(mu_0).numpy()\n",
    "        \n",
    "        e2_mu0 = sc.norm.pdf(mu,loc = 0, scale = self.sigma)\n",
    "        e2_mu = dismix_mu.prob(mu).numpy()\n",
    "\n",
    "        return e1_mu0, e1_mu, e2_mu0, e2_mu\n",
    "                            \n",
    "    def _compute_moment(self, lambd: np.array):\n",
    "        '''\n",
    "        CHECKED - WORKING CORRECTLY\n",
    "        '''\n",
    "        # computes unbiased expectation for E1 & E2, then the moment alpha \n",
    "        lambd = np.broadcast_to(np.expand_dims(lambd, -1), (self.lambdaN, self.mixN)) # broadcast\n",
    "        #E1 = 1/self.mixN*np.sum(np.transpose(np.power(np.transpose(self.mu_0/self.mu),lambd)), axis = 0)\n",
    "        #E2 = 1/self.mixN*np.sum(np.transpose(np.power(np.transpose(self.mu/self.mu_0),lambd)), axis = 0)\n",
    "        E1 = np.nanmean(np.transpose(np.power(np.transpose(self.e1_mu0/self.e1_mu),lambd)), axis = 0)\n",
    "        '''\n",
    "        note that due to setup E1 will always be < 1 since denom > num always\n",
    "        '''\n",
    "        E2 = np.nanmean(np.transpose(np.power(np.transpose(self.e2_mu/self.e2_mu0),lambd)), axis = 0)\n",
    "        '''\n",
    "        note that due to setup E2 will always be > 1 since denom < num always\n",
    "        '''\n",
    "        #alpha = np.log(np.maximum(E1,E2))\n",
    "        alpha = np.log(np.maximum(E1,E2))\n",
    "        return alpha\n",
    "    \n",
    "    def compute_deltaEps(self):\n",
    "        # tail bound\n",
    "        #alpha = self._compute_moment(self.lambd) + self.alpha # note that this is the log moment!\n",
    "        alpha = self.alphaSum + self.alpha # note that this is the log moment!\n",
    "        self.alphaSum = alpha # update moment\n",
    "        if self.epsFixed:\n",
    "            # epsilon is kept fixed, compute delta\n",
    "            epsilon = self.epsilon\n",
    "            delta = np.min(np.exp(alpha-self.lambd*epsilon))\n",
    "            # TODO remove inf or nan <- does not seem necessary\n",
    "            if self.debug:\n",
    "                ind = np.argmin(np.exp(alpha-self.lambd*epsilon))\n",
    "                self.lambdArgmin.append(self.lambd[ind])\n",
    "        if self.deltaFixed:\n",
    "            # delta is kept fixed, compute epsilon\n",
    "            delta = self.delta\n",
    "            epsilon = (alpha-np.log(delta))/self.lambd\n",
    "            if self.debug:\n",
    "                ind = np.argmin(epsilon)\n",
    "                self.lambdArgmin.append(self.lambd[ind])\n",
    "            epsilon = np.min(epsilon)\n",
    "            # TODO remove inf or nan <- does not seem necessary\n",
    "        self.epsList.append(epsilon)\n",
    "        self.deltaList.append(delta)\n",
    "        return delta, epsilon\n",
    "    \n",
    "    def check_thresholds(self, delta: float, epsilon: float):\n",
    "        go = True\n",
    "        if self.epsFixed:\n",
    "            if self.th_delta < delta: \n",
    "                # delta threshold exceeded\n",
    "                go = False\n",
    "        if self.deltaFixed:\n",
    "            if self.th_epsilon < epsilon:\n",
    "                # epsilon threshold exceeded\n",
    "                go = False\n",
    "        return go\n",
    "    \n",
    "    def plot_traces(self):\n",
    "        if len(self.epsList) == 0:\n",
    "            raise Exception(\"Apply iterations on accountant instance before calling this function\")\n",
    "        elif not self.debug:\n",
    "            raise Exception(\"Debug was set to false, thus not all relevant data was collected\")\n",
    "        else:\n",
    "            # gather data\n",
    "            epsilon = np.array(self.epsList)\n",
    "            delta = np.array(self.deltaList)\n",
    "            lambdas = np.array(self.lambdArgmin)\n",
    "            print(f\"Delta fixed = {self.deltaFixed}| Last delta = {delta[-1]}\")\n",
    "            print(f\"Epsilon fixed = {self.epsFixed}| Last epsilon = {epsilon[-1]}\")\n",
    "            print(\"Fixed parameter will not be plotted \\n NOTE: Iteration arrays are returned\")\n",
    "            # plotting\n",
    "            iterations = np.arange(0,len(epsilon))\n",
    "            plt.figure()\n",
    "            if self.deltaFixed:\n",
    "                plt.plot(iterations,epsilon, label = 'epsilon')\n",
    "            else:\n",
    "                plt.plot(iterations,delta, label = 'delta')\n",
    "            #plt.legend(loc='upper left')\n",
    "            plt.title(\"epsilon or delta over iterations\")\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(iterations,lambdas)\n",
    "            plt.title(\"Lambda chosen over iterations\")\n",
    "            \n",
    "        return delta, epsilon, lambdas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accountant = moment_accountant(seed, parameters_ma, deltaFixed = deltaFixed, epsFixed= epsFixed, debug = debug, epsilon = epsilon, th_delta = th_delta)\n",
    "for i in range(0,20):\n",
    "    print(accountant.compute_deltaEps())\n",
    "    #print(accountant.alphaSum)\n",
    "accountant.plot_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO/QUESTIONS\n",
    "- Is the following assumption true: the moment accountant random variable is independent of the rest of the system (offline), that said it is only connected to the system by its continuous call to it (causing the moment to grow)\n",
    "- maxorder? 32 and also can it be floats?\n",
    "- ASSUMPTION: q is so small that essentially the pdf_mu0 distribution stands? is this correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVFI54MpQUDp"
   },
   "source": [
    "## Differential privary variant of SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DP_SGD:\n",
    "    def __init__(self, lr = 0.01, sigma = 0.2, gs = 10, C = 1, seed = 2): # TODO; check defaults\n",
    "        self.lr = lr # learning rate\n",
    "        self.sigma = sigma # sigma, noise scale\n",
    "        self.gs = gs # group size\n",
    "        self.C = C # gradient norm bound\n",
    "        self.seed = seed\n",
    "        self.std = sigma*C # for noise addition\n",
    "        #self.loss_object = ? # define this here\n",
    "        \n",
    "    def apply_gradients(self, optimizer, model, loss_object, x, y):\n",
    "\n",
    "        #n = tf.shape(x).numpy()\n",
    "        ## run loop\n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            y_pred = model(x)\n",
    "            loss = loss_object(y, y_pred)\n",
    "            loss_red = tf.reduce_sum(loss, axis = 0)\n",
    "            \n",
    "            \n",
    "        #########\n",
    "        # MAIN PROBLEM: I only get a single set of gradients even if i have a loss function which outputs loss for every sample\n",
    "        # do you want me to parallelize this myself\n",
    "        ########\n",
    "        ## obtain gradients    \n",
    "        #grad = tape.batch_jacobian(loss, model.trainable_weights)\n",
    "        grad = tape.jacobian(loss, model.trainable_weights, parallel_iterations = None, experimental_use_pfor= False)\n",
    "        \n",
    "        ## clip gradients per layer\n",
    "        for l in range(len(grad)):\n",
    "            #clipper = tf.norm(grad[l], ord = 2, axis = 0)\n",
    "            dims = len(tf.shape(grad[l]))\n",
    "            clipper = tf.math.square(grad[l])\n",
    "            \n",
    "            if dims > 2:\n",
    "                # kernel layers\n",
    "                clipper = tf.reduce_sum(clipper, axis = [1,2])\n",
    "            else:\n",
    "                # bias layer\n",
    "                clipper = tf.reduce_sum(clipper, axis = -1)\n",
    "                \n",
    "            clipper = tf.math.sqrt(clipper)\n",
    "            clipper = tf.math.maximum(tf.constant([1], dtype = tf.dtypes.float32),clipper/self.C)\n",
    "            if dims > 2:\n",
    "                # kernel layers\n",
    "                clipper = tf.broadcast_to(tf.expand_dims(tf.expand_dims(clipper, -1), -1),tf.shape(grad[l]))\n",
    "            else:\n",
    "                # bias layer\n",
    "                clipper = tf.broadcast_to(tf.expand_dims(clipper, -1),tf.shape(grad[l]))\n",
    "            grad[l] = tf.math.divide(grad[l],clipper) # override\n",
    "                \n",
    "        ## add noise\n",
    "        for l in range(len(grad)): # loop over layers\n",
    "            grad_red = tf.math.reduce_sum(grad[l], axis = 0)\n",
    "            shape = tf.shape(grad_red)\n",
    "            noise = tf.random.normal(shape, mean = 0, stddev = self.std, dtype=tf.dtypes.float32, seed=self.seed)\n",
    "            grad[l] = tf.add(grad_red, noise)/self.gs\n",
    "            \n",
    "\n",
    "\n",
    "        ## descent\n",
    "        #print(grad)\n",
    "        '''\n",
    "        print(f'HELOO={len(grad)}')\n",
    "        print(f'HELOO={len(model.trainable_weights)}')\n",
    "        ga = []\n",
    "        ma = []\n",
    "        print(type(model.trainable_weights))\n",
    "        for l in range(len(model.trainable_weights)):\n",
    "            ga.append(tf.shape(grad[l]).numpy())\n",
    "            ma.append(tf.shape(model.trainable_weights[l]).numpy())\n",
    "        zipp = list(zip(ga,ma))\n",
    "        print(zipp)\n",
    "        \n",
    "        #print(model.trainable_weights)\n",
    "        '''\n",
    "        \n",
    "        optimizer.apply_gradients(zip(grad,model.trainable_weights))\n",
    "            \n",
    "        ## collect\n",
    "    \n",
    "        return y_pred,loss_red \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIPTOTAL VARIANT\n",
    "class DP_SGD:\n",
    "    def __init__(self, lr = 0.01, sigma = 0.2, gs = 10, C = 1, seed = 2): # TODO; check defaults\n",
    "        self.lr = lr # learning rate\n",
    "        self.sigma = sigma # sigma, noise scale\n",
    "        self.gs = gs # group size\n",
    "        self.C = C # gradient norm bound\n",
    "        self.seed = seed\n",
    "        self.std = sigma*C # for noise addition\n",
    "        #self.loss_object = ? # define this here\n",
    "        \n",
    "    def apply_gradients(self, optimizer, model, loss_object, x, y):\n",
    "\n",
    "        #n = tf.shape(x).numpy()\n",
    "        ## run loop\n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            y_pred = model(x)\n",
    "            loss = loss_object(y, y_pred)\n",
    "            loss_red = tf.reduce_sum(loss, axis = 0)\n",
    "            \n",
    "            \n",
    "        #########\n",
    "        # MAIN PROBLEM: I only get a single set of gradients even if i have a loss function which outputs loss for every sample\n",
    "        # do you want me to parallelize this myself\n",
    "        ########\n",
    "        ## obtain gradients    \n",
    "        #grad = tape.batch_jacobian(loss, model.trainable_weights)\n",
    "        grad = tape.jacobian(loss, model.trainable_weights, parallel_iterations = None, experimental_use_pfor= False)\n",
    "        clipTotal = tf.constant([0], dtype = tf.dtypes.float32)\n",
    "        \n",
    "        ## clip gradients per layer\n",
    "        for l in range(len(grad)):\n",
    "            #clipper = tf.norm(grad[l], ord = 2, axis = 0)\n",
    "            dims = len(tf.shape(grad[l]))\n",
    "            clipper = tf.math.square(grad[l])\n",
    "            \n",
    "            if dims > 2:\n",
    "                # kernel layers\n",
    "                clipper = tf.reduce_sum(clipper, axis = [1,2])\n",
    "            else:\n",
    "                # bias layer\n",
    "                clipper = tf.reduce_sum(clipper, axis = -1)\n",
    "                \n",
    "            clipTotal = tf.add(clipTotal, clipper)\n",
    "            \n",
    "        clipTotal = tf.math.sqrt(clipTotal)\n",
    "        clipTotal = tf.math.maximum(tf.constant([1], dtype = tf.dtypes.float32),clipTotal/self.C)\n",
    "                \n",
    "        ## add noise\n",
    "        for l in range(len(grad)): # loop over layers\n",
    "            dims = len(tf.shape(grad[l]))\n",
    "            if dims > 2:\n",
    "                # kernel layers\n",
    "                clipper = tf.broadcast_to(tf.expand_dims(tf.expand_dims(clipTotal, -1), -1),tf.shape(grad[l]))\n",
    "            else:\n",
    "                # bias layer\n",
    "                clipper = tf.broadcast_to(tf.expand_dims(clipTotal, -1),tf.shape(grad[l]))\n",
    "            grad[l] = tf.math.divide(grad[l],clipper) # override\n",
    "            \n",
    "            grad_red = tf.math.reduce_sum(grad[l], axis = 0)\n",
    "            shape = tf.shape(grad_red)\n",
    "            noise = tf.random.normal(shape, mean = 0, stddev = self.std, dtype=tf.dtypes.float32, seed=self.seed)\n",
    "            grad[l] = tf.add(grad_red, noise)/self.gs\n",
    "            \n",
    "        ## descent\n",
    "        optimizer.apply_gradients(zip(grad,model.trainable_weights))\n",
    "            \n",
    "        ## collect\n",
    "    \n",
    "        return y_pred,loss_red "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer, model, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss_value = loss_object(y_true=y, y_pred=logits)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights)) # ZIP ENSURES THAT GRADIENTS IS APPLIED TO EVERY LAYER CORRECTLY (SINCE EVERY LAYER HAS W & b != not 1 variable)\n",
    "\n",
    "    return logits, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_for_one_epoch(dp_sgd, optimizer, model, loss_object, moment_accountant):\n",
    "    losses = []\n",
    "    pbar = tqdm(total=len(list(enumerate(train))), position=0, leave=True, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ') # progress bar\n",
    "    go = True\n",
    "    step = 0 \n",
    "    for x_batch_train, y_batch_train in train:\n",
    "        step += 1\n",
    "        logits, loss_value = dp_sgd.apply_gradients(optimizer, model, loss_object, x_batch_train, y_batch_train)\n",
    "        #logits, loss_value = apply_gradient(optimizer, model, x_batch_train, y_batch_train)\n",
    "        delta, eps = moment_accountant.compute_deltaEps()\n",
    "        \n",
    "        losses.append(loss_value)\n",
    "\n",
    "        train_acc_metric(y_batch_train, logits)\n",
    "        pbar.set_description(\"Training loss for step %s: %.4f\" % (int(step), float(loss_value)))\n",
    "        pbar.update()\n",
    "        \n",
    "        if not moment_accountant.check_thresholds(delta, epsilon):\n",
    "            go = False\n",
    "            break\n",
    "    print(f\"Delta = {delta} | Epsilon = {epsilon}\")\n",
    "    return losses, go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBZyXnuUQxVn"
   },
   "source": [
    "At the end of each epoch you have to validate the model on the test dataset. The following function calculates the loss on test dataset and updates the states of the validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gLJyAJE0YRc"
   },
   "outputs": [],
   "source": [
    "def perform_validation():\n",
    "    losses = []\n",
    "    for x_val, y_val in test:\n",
    "        val_logits = model(x_val)\n",
    "        val_loss = loss_object(y_val, val_logits)\n",
    "        #val_loss = tf.reduce_sum(val_loss, axis = 0).numpy()\n",
    "        losses.append(val_loss)\n",
    "        val_acc_metric(y_val, val_logits)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxorder = 32, with order array:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32]\n",
      "keeping epsilon fixed\n",
      "moment accountant setup complete\n",
      "Delta fixed = False| Last delta = 7.3130754258017764e-06\n",
      "Epsilon fixed = True| Last epsilon = 2\n",
      "Fixed parameter will not be plotted \n",
      " NOTE: Iteration arrays are returned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.61157896e-28, 1.61938465e-28, 1.62722815e-28, ...,\n",
       "        7.28717560e-06, 7.30011403e-06, 7.31307543e-06]),\n",
       " array([2, 2, 2, ..., 2, 2, 2]),\n",
       " array([32, 32, 32, ..., 17, 17, 17]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accountant = moment_accountant(seed, parameters_ma, deltaFixed = deltaFixed, epsFixed= epsFixed, debug = debug, epsilon = epsilon, th_delta = th_delta)\n",
    "for i in range(12500):\n",
    "    accountant.compute_deltaEps()\n",
    "accountant.plot_traces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOO1x3VyuPUV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method DP_PCA.call of <__main__.DP_PCA object at 0x0000017838793F48>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " digits (InputLayer)         [(None, 784)]             0         \n",
      "                                                                 \n",
      " dp_pca (DP_PCA)             (None, 60)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              61000     \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,010\n",
      "Trainable params: 71,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                          | 0/100 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epsilon kept fixed \n",
      "\n",
      "Maxorder = 32, with order array:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32]\n",
      "keeping epsilon fixed\n",
      "moment accountant setup complete\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 100: 430.8535: 100%|| 100/100 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta = 1.4758626944157784e-07 | Epsilon = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                          | 0/100 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 0: Train loss: 771.5447  Validation Loss: 0.7332, Train Accuracy: 0.6049, Validation Accuracy 0.7786\n",
      "Start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 3: 489.6414:   3%|                                                                    | 3/100 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b11f149abd8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start of epoch %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mlosses_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_for_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDPSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccountant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_acc_metric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-8edaad4467be>\u001b[0m in \u001b[0;36mtrain_data_for_one_epoch\u001b[1;34m(dp_sgd, optimizer, model, loss_object, moment_accountant)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch_train\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdp_sgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;31m#logits, loss_value = apply_gradient(optimizer, model, x_batch_train, y_batch_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmoment_accountant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_deltaEps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-aa7eb82d9618>\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, optimizer, model, loss_object, x, y)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m## obtain gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m#grad = tape.batch_jacobian(loss, model.trainable_weights)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperimental_use_pfor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m## clip gradients per layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mjacobian\u001b[1;34m(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)\u001b[0m\n\u001b[0;32m   1198\u001b[0m       output = pfor_ops.for_loop(\n\u001b[0;32m   1199\u001b[0m           \u001b[0mloop_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_sources\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m           parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py\u001b[0m in \u001b[0;36mfor_loop\u001b[1;34m(loop_fn, loop_fn_dtypes, iters, parallel_iterations)\u001b[0m\n\u001b[0;32m     92\u001b[0m       [0] + [tensor_array_ops.TensorArray(dtype.base_dtype, iters)\n\u001b[0;32m     93\u001b[0m              for dtype in flat_loop_fn_dtypes],\n\u001b[1;32m---> 94\u001b[1;33m       **extra_args)[1:]\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m   \u001b[1;31m# TODO(rachelim): enable this for sparse tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2793\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2794\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2795\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\parallel_for\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_body\u001b[1;34m(i, *ta_list)\u001b[0m\n\u001b[0;32m     66\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwhile_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mta_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;34m\"\"\"Body of while loop.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mfn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_output\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_loop_fn_dtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mloop_fn\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       return self.gradient(y, flat_sources,\n\u001b[1;32m-> 1173\u001b[1;33m                            unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_GatherV2Grad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    647\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mparams_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m     \u001b[0mparams_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m   \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m   1000\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1003\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 1997\u001b[1;33m         _ctx, \"Cast\", name, x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[0;32m   1998\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## INITIALIZE \n",
    "model = base_model()\n",
    "model.layers[2].trainable = False # pca layer\n",
    "DPSGD = DP_SGD(lr_sgd,std_sgd, gs, C, seed)\n",
    "if epsFixed: \n",
    "    print(\"\\n Epsilon kept fixed \\n\")\n",
    "    accountant = moment_accountant(seed, parameters_ma, deltaFixed = deltaFixed, epsFixed= epsFixed, debug = debug, epsilon = epsilon, th_delta = th_delta)\n",
    "else:\n",
    "    print(\"\\n Delta kept fixed \\n\")\n",
    "    #delta fixed\n",
    "    accountant = moment_accountant(seed, parameters_ma, deltaFixed = deltaFixed, epsFixed= epsFixed, debug = debug, delta = delta, th_epsilon = th_epsilon)\n",
    "\n",
    "# Iterate over epochs.\n",
    "epochs = 110 #18\n",
    "epochs_val_losses, epochs_train_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    losses_train, go = train_data_for_one_epoch(DPSGD, optimizer, model, loss_object, accountant)\n",
    "    train_acc = train_acc_metric.result()\n",
    "\n",
    "    losses_val = perform_validation()\n",
    "    val_acc = val_acc_metric.result()\n",
    "\n",
    "    losses_train_mean = np.mean(losses_train)\n",
    "    losses_val_mean = np.mean(losses_val)\n",
    "    epochs_val_losses.append(losses_val_mean)\n",
    "    epochs_train_losses.append(losses_train_mean)\n",
    "\n",
    "    print('\\n Epoch %s: Train loss: %.4f  Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f' % (epoch, float(losses_train_mean), float(losses_val_mean), float(train_acc), float(val_acc)))\n",
    "\n",
    "    train_acc_metric.reset_states()\n",
    "    val_acc_metric.reset_states()\n",
    "    if not go:\n",
    "        print(f\"\\n Stopping due to privacy loss at epoch {epoch}/{epochs} \\n\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltKpkpzKK_Up"
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfGc-gMPLCDn"
   },
   "source": [
    "### Plots for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjzIlGipJwC_"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(train_metric, val_metric, metric_name, title, ylim=5):\n",
    "    plt.title(title)\n",
    "    #plt.ylim(0,ylim)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    x = np.arange(1,len(train_metric)+1)\n",
    "    plt.plot(x,train_metric,color='blue',label=metric_name)\n",
    "    plt.plot(x,val_metric,color='green',label='val_' + metric_name)\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(epochs_train_losses, epochs_val_losses, \"Loss\", \"Loss\", ylim=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clock = time.localtime(time.time())\n",
    "runName = f'run_d{clock.tm_mday}h{clock.tm_hour}m{clock.tm_min}'\n",
    "print(runName)\n",
    "pathName = f'./models/{runName}'\n",
    "model.save(pathName)\n",
    "with open(f'./models/{runName}/{runName}_parameters.txt', 'w') as f:\n",
    "    print(allParameters, file=f)\n",
    "with open(f'./models/{runName}/delta_epsilon_lambda_.npy', 'wb') as f:\n",
    "    np.save(f, np.array(accountant.deltaList))\n",
    "    np.save(f, np.array(accountant.epsList))\n",
    "'''\n",
    "# get arrays back\n",
    "with open(f'./models/{runName}/delta_epsilon_lambda_.npy', 'rb') as f:\n",
    "    deltas = np.load(np.array(accountant.deltaList))\n",
    "    epsilons = np.load(np.array(accountant.epsList))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adpLKxFfZzTD"
   },
   "source": [
    "This function displays a row of images with their predictions and true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_3PJnCRIO8bM"
   },
   "source": [
    "# Utility function\n",
    "## utility to display a row of images with their predictions and true labels\n",
    "def display_images(image, predictions, labels, title, n):\n",
    "\n",
    "    display_strings = [str(i) + \"\\n\\n\" + str(j) for i, j in zip(predictions, labels)] \n",
    "\n",
    "    plt.figure(figsize=(17,3))\n",
    "    plt.title(title)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([28*x+14 for x in range(n)], display_strings)\n",
    "    plt.grid(None)\n",
    "    image = np.reshape(image, [n, 28, 28])\n",
    "    image = np.swapaxes(image, 0, 1)\n",
    "    image = np.reshape(image, [28, 28*n])\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "505DveJuaCNO"
   },
   "source": [
    "You make predictions on the test dataset and plot the images with their true and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ybveIIcPgVr"
   },
   "source": [
    "# display random predicted labels\n",
    "test_inputs = test_data.batch(batch_size=1000001)\n",
    "x_batches, y_pred_batches, y_true_batches = [], [], []\n",
    "\n",
    "for x, y in test_inputs:\n",
    "    y_pred = model(x)\n",
    "    y_pred_batches = y_pred.numpy()\n",
    "    y_true_batches = y.numpy()\n",
    "    x_batches = x.numpy()\n",
    "\n",
    "indexes = np.random.choice(len(y_pred_batches), size=10)\n",
    "images_to_plot = x_batches[indexes]\n",
    "y_pred_to_plot = y_pred_batches[indexes]\n",
    "y_true_to_plot = y_true_batches[indexes]\n",
    "\n",
    "y_pred_labels = [class_names[np.argmax(sel_y_pred)] for sel_y_pred in y_pred_to_plot]\n",
    "y_true_labels = [class_names[sel_y_true] for sel_y_true in y_true_to_plot]\n",
    "display_images(images_to_plot, y_pred_labels, y_true_labels, \"Predicted and True Values\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Training Categorical.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
